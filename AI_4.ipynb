{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7-qwt9hhwBfc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Organize and Load the Datasets\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzW3o4RIwH5B",
        "outputId": "992a9bd0-46c5-4a4e-942d-2e5fbd42d0b0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Directories containing the datasets\n",
        "small_data_dir = '/content/drive/My Drive/CS205_small_Data'\n",
        "large_data_dir = '/content/drive/My Drive/CS205_large_Data'"
      ],
      "metadata": {
        "id": "aleNo7YtwSRl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load and normalize a dataset\n",
        "def load_and_normalize_dataset(file_path):\n",
        "    data = np.loadtxt(file_path)\n",
        "    X = data[:, 1:]\n",
        "    y = data[:, 0].astype(int)\n",
        "    X = (X - np.mean(X, axis=0)) / np.std(X, axis=0)  # Normalize features\n",
        "    return X, y\n",
        "\n",
        "# Function to normalize features\n",
        "def normalize_features(X):\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "    return X_scaled"
      ],
      "metadata": {
        "id": "UhmrO_LswTVC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement the Nearest Neighbor Classifier\n",
        "def nearest_neighbor(X_train, y_train, X_test):\n",
        "    predictions = []\n",
        "    for test_instance in X_test:\n",
        "        distances = np.linalg.norm(X_train - test_instance, axis=1)\n",
        "        nearest_index = np.argmin(distances)\n",
        "        predictions.append(y_train[nearest_index])\n",
        "    return np.array(predictions)"
      ],
      "metadata": {
        "id": "U9LSMIoUwYjt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Selection Methods\n",
        "def forward_selection(X, y):\n",
        "    n_features = X.shape[1]\n",
        "    selected_features = []\n",
        "    best_accuracy = 0\n",
        "\n",
        "    print(\"Beginning search.\\n\")\n",
        "\n",
        "    for _ in range(n_features):\n",
        "        best_feature = None\n",
        "        for feature in range(n_features):\n",
        "            if feature in selected_features:\n",
        "                continue\n",
        "            features_to_test = selected_features + [feature]\n",
        "            accuracy = cross_val_accuracy(X[:, features_to_test], y)\n",
        "            print(f\"Using feature(s) {features_to_test} accuracy is {accuracy * 100:.1f}%\")\n",
        "            if accuracy > best_accuracy:\n",
        "                best_accuracy = accuracy\n",
        "                best_feature = feature\n",
        "        if best_feature is not None:\n",
        "            selected_features.append(best_feature)\n",
        "            print(f\"Feature set {selected_features} was best, accuracy is {best_accuracy * 100:.1f}%\\n\")\n",
        "\n",
        "    return selected_features\n",
        "\n",
        "def backward_elimination(X, y):\n",
        "    n_features = X.shape[1]\n",
        "    selected_features = list(range(n_features))\n",
        "    best_accuracy = cross_val_accuracy(X, y)\n",
        "\n",
        "    for _ in range(n_features):\n",
        "        worst_feature = None\n",
        "        for feature in selected_features:\n",
        "            features_to_test = [f for f in selected_features if f != feature]\n",
        "            accuracy = cross_val_accuracy(X[:, features_to_test], y)\n",
        "            if accuracy > best_accuracy:\n",
        "                best_accuracy = accuracy\n",
        "                worst_feature = feature\n",
        "        if worst_feature is not None:\n",
        "            selected_features.remove(worst_feature)\n",
        "    return selected_features"
      ],
      "metadata": {
        "id": "C5IuEqk_wenu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Performance\n",
        "def cross_val_accuracy(X, y, k=5):\n",
        "    accuracies = []\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "    y_pred = nearest_neighbor(X_train, y_train, X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    accuracies.append(accuracy)\n",
        "    return np.mean(accuracies)"
      ],
      "metadata": {
        "id": "hM_NYkiOwrhO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt the user to input the file name\n",
        "file_name = input(\"Type in the file name to test: \")\n",
        "\n",
        "# Check if the file exists in the specified directories\n",
        "small_data_dir = '/content/drive/My Drive/CS205_small_Data'\n",
        "large_data_dir = '/content/drive/My Drive/CS205_large_Data'\n",
        "\n",
        "file_path = None\n",
        "small_file_path = os.path.join(small_data_dir, file_name)\n",
        "large_file_path = os.path.join(large_data_dir, file_name)\n",
        "\n",
        "if os.path.exists(small_file_path):\n",
        "    file_path = small_file_path\n",
        "elif os.path.exists(large_file_path):\n",
        "    file_path = large_file_path\n",
        "else:\n",
        "    print(\"File not found in the specified directories.\")\n",
        "    exit()\n",
        "\n",
        "# Load and normalize the dataset\n",
        "if file_path:\n",
        "    X, y = load_and_normalize_dataset(file_path)\n",
        "\n",
        "    print(f\"This dataset has {X.shape[1]} features (not including the class attribute), with {X.shape[0]} instances.\\n\")\n",
        "    print(f\"Running nearest neighbor with all {X.shape[1]} features, using 'leaving-one-out' evaluation, I get an accuracy of {cross_val_accuracy(X, y) * 100:.1f}%\\n\")\n",
        "\n",
        "    # Perform Feature Selection and Evaluate\n",
        "    print(\"Beginning search.\\n\")\n",
        "\n",
        "    # Forward Selection\n",
        "    print(\"Forward Selection\")\n",
        "    selected_features_forward = forward_selection(X, y)\n",
        "    accuracy_forward = cross_val_accuracy(X[:, selected_features_forward], y)\n",
        "    print(f\"Finished search!! The best feature subset is {selected_features_forward}, which has an accuracy of {accuracy_forward * 100:.1f}%\\n\")\n",
        "\n",
        "    # Backward Elimination\n",
        "    print(\"Backward Elimination\")\n",
        "    selected_features_backward = backward_elimination(X, y)\n",
        "    accuracy_backward = cross_val_accuracy(X[:, selected_features_backward], y)\n",
        "    print(f\"Finished search!! The best feature subset is {selected_features_backward}, which has an accuracy of {accuracy_backward * 100:.1f}%\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xE-hocy0wxBk",
        "outputId": "5b721039-3f76-46d3-d4da-d8cada51fc2e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type in the file name to test: CS205_small_Data__5.txt\n",
            "This dataset has 12 features (not including the class attribute), with 500 instances.\n",
            "\n",
            "Running nearest neighbor with all 12 features, using 'leaving-one-out' evaluation, I get an accuracy of 70.0%\n",
            "\n",
            "Beginning search.\n",
            "\n",
            "Forward Selection\n",
            "Beginning search.\n",
            "\n",
            "Using feature(s) [0] accuracy is 68.0%\n",
            "Using feature(s) [1] accuracy is 73.0%\n",
            "Using feature(s) [2] accuracy is 64.0%\n",
            "Using feature(s) [3] accuracy is 69.0%\n",
            "Using feature(s) [4] accuracy is 57.0%\n",
            "Using feature(s) [5] accuracy is 74.0%\n",
            "Using feature(s) [6] accuracy is 87.0%\n",
            "Using feature(s) [7] accuracy is 70.0%\n",
            "Using feature(s) [8] accuracy is 56.0%\n",
            "Using feature(s) [9] accuracy is 59.0%\n",
            "Using feature(s) [10] accuracy is 64.0%\n",
            "Using feature(s) [11] accuracy is 64.0%\n",
            "Feature set [6] was best, accuracy is 87.0%\n",
            "\n",
            "Using feature(s) [6, 0] accuracy is 81.0%\n",
            "Using feature(s) [6, 1] accuracy is 73.0%\n",
            "Using feature(s) [6, 2] accuracy is 82.0%\n",
            "Using feature(s) [6, 3] accuracy is 77.0%\n",
            "Using feature(s) [6, 4] accuracy is 81.0%\n",
            "Using feature(s) [6, 5] accuracy is 97.0%\n",
            "Using feature(s) [6, 7] accuracy is 87.0%\n",
            "Using feature(s) [6, 8] accuracy is 72.0%\n",
            "Using feature(s) [6, 9] accuracy is 79.0%\n",
            "Using feature(s) [6, 10] accuracy is 81.0%\n",
            "Using feature(s) [6, 11] accuracy is 78.0%\n",
            "Feature set [6, 5] was best, accuracy is 97.0%\n",
            "\n",
            "Using feature(s) [6, 5, 0] accuracy is 90.0%\n",
            "Using feature(s) [6, 5, 1] accuracy is 94.0%\n",
            "Using feature(s) [6, 5, 2] accuracy is 93.0%\n",
            "Using feature(s) [6, 5, 3] accuracy is 96.0%\n",
            "Using feature(s) [6, 5, 4] accuracy is 92.0%\n",
            "Using feature(s) [6, 5, 7] accuracy is 90.0%\n",
            "Using feature(s) [6, 5, 8] accuracy is 91.0%\n",
            "Using feature(s) [6, 5, 9] accuracy is 93.0%\n",
            "Using feature(s) [6, 5, 10] accuracy is 89.0%\n",
            "Using feature(s) [6, 5, 11] accuracy is 90.0%\n",
            "Using feature(s) [6, 5, 0] accuracy is 91.0%\n",
            "Using feature(s) [6, 5, 1] accuracy is 90.0%\n",
            "Using feature(s) [6, 5, 2] accuracy is 90.0%\n",
            "Using feature(s) [6, 5, 3] accuracy is 90.0%\n",
            "Using feature(s) [6, 5, 4] accuracy is 88.0%\n",
            "Using feature(s) [6, 5, 7] accuracy is 85.0%\n",
            "Using feature(s) [6, 5, 8] accuracy is 91.0%\n",
            "Using feature(s) [6, 5, 9] accuracy is 87.0%\n",
            "Using feature(s) [6, 5, 10] accuracy is 92.0%\n",
            "Using feature(s) [6, 5, 11] accuracy is 88.0%\n",
            "Using feature(s) [6, 5, 0] accuracy is 90.0%\n",
            "Using feature(s) [6, 5, 1] accuracy is 89.0%\n",
            "Using feature(s) [6, 5, 2] accuracy is 91.0%\n",
            "Using feature(s) [6, 5, 3] accuracy is 90.0%\n",
            "Using feature(s) [6, 5, 4] accuracy is 89.0%\n",
            "Using feature(s) [6, 5, 7] accuracy is 95.0%\n",
            "Using feature(s) [6, 5, 8] accuracy is 95.0%\n",
            "Using feature(s) [6, 5, 9] accuracy is 92.0%\n",
            "Using feature(s) [6, 5, 10] accuracy is 94.0%\n",
            "Using feature(s) [6, 5, 11] accuracy is 93.0%\n",
            "Using feature(s) [6, 5, 0] accuracy is 86.0%\n",
            "Using feature(s) [6, 5, 1] accuracy is 91.0%\n",
            "Using feature(s) [6, 5, 2] accuracy is 91.0%\n",
            "Using feature(s) [6, 5, 3] accuracy is 93.0%\n",
            "Using feature(s) [6, 5, 4] accuracy is 92.0%\n",
            "Using feature(s) [6, 5, 7] accuracy is 93.0%\n",
            "Using feature(s) [6, 5, 8] accuracy is 89.0%\n",
            "Using feature(s) [6, 5, 9] accuracy is 91.0%\n",
            "Using feature(s) [6, 5, 10] accuracy is 87.0%\n",
            "Using feature(s) [6, 5, 11] accuracy is 92.0%\n",
            "Using feature(s) [6, 5, 0] accuracy is 91.0%\n",
            "Using feature(s) [6, 5, 1] accuracy is 94.0%\n",
            "Using feature(s) [6, 5, 2] accuracy is 91.0%\n",
            "Using feature(s) [6, 5, 3] accuracy is 89.0%\n",
            "Using feature(s) [6, 5, 4] accuracy is 92.0%\n",
            "Using feature(s) [6, 5, 7] accuracy is 87.0%\n",
            "Using feature(s) [6, 5, 8] accuracy is 89.0%\n",
            "Using feature(s) [6, 5, 9] accuracy is 85.0%\n",
            "Using feature(s) [6, 5, 10] accuracy is 94.0%\n",
            "Using feature(s) [6, 5, 11] accuracy is 94.0%\n",
            "Using feature(s) [6, 5, 0] accuracy is 86.0%\n",
            "Using feature(s) [6, 5, 1] accuracy is 92.0%\n",
            "Using feature(s) [6, 5, 2] accuracy is 90.0%\n",
            "Using feature(s) [6, 5, 3] accuracy is 88.0%\n",
            "Using feature(s) [6, 5, 4] accuracy is 93.0%\n",
            "Using feature(s) [6, 5, 7] accuracy is 90.0%\n",
            "Using feature(s) [6, 5, 8] accuracy is 88.0%\n",
            "Using feature(s) [6, 5, 9] accuracy is 94.0%\n",
            "Using feature(s) [6, 5, 10] accuracy is 92.0%\n",
            "Using feature(s) [6, 5, 11] accuracy is 85.0%\n",
            "Using feature(s) [6, 5, 0] accuracy is 88.0%\n",
            "Using feature(s) [6, 5, 1] accuracy is 88.0%\n",
            "Using feature(s) [6, 5, 2] accuracy is 93.0%\n",
            "Using feature(s) [6, 5, 3] accuracy is 91.0%\n",
            "Using feature(s) [6, 5, 4] accuracy is 92.0%\n",
            "Using feature(s) [6, 5, 7] accuracy is 91.0%\n",
            "Using feature(s) [6, 5, 8] accuracy is 94.0%\n",
            "Using feature(s) [6, 5, 9] accuracy is 90.0%\n",
            "Using feature(s) [6, 5, 10] accuracy is 87.0%\n",
            "Using feature(s) [6, 5, 11] accuracy is 95.0%\n",
            "Using feature(s) [6, 5, 0] accuracy is 87.0%\n",
            "Using feature(s) [6, 5, 1] accuracy is 83.0%\n",
            "Using feature(s) [6, 5, 2] accuracy is 91.0%\n",
            "Using feature(s) [6, 5, 3] accuracy is 94.0%\n",
            "Using feature(s) [6, 5, 4] accuracy is 88.0%\n",
            "Using feature(s) [6, 5, 7] accuracy is 90.0%\n",
            "Using feature(s) [6, 5, 8] accuracy is 91.0%\n",
            "Using feature(s) [6, 5, 9] accuracy is 95.0%\n",
            "Using feature(s) [6, 5, 10] accuracy is 92.0%\n",
            "Using feature(s) [6, 5, 11] accuracy is 88.0%\n",
            "Using feature(s) [6, 5, 0] accuracy is 90.0%\n",
            "Using feature(s) [6, 5, 1] accuracy is 88.0%\n",
            "Using feature(s) [6, 5, 2] accuracy is 93.0%\n",
            "Using feature(s) [6, 5, 3] accuracy is 96.0%\n",
            "Using feature(s) [6, 5, 4] accuracy is 88.0%\n",
            "Using feature(s) [6, 5, 7] accuracy is 88.0%\n",
            "Using feature(s) [6, 5, 8] accuracy is 94.0%\n",
            "Using feature(s) [6, 5, 9] accuracy is 87.0%\n",
            "Using feature(s) [6, 5, 10] accuracy is 90.0%\n",
            "Using feature(s) [6, 5, 11] accuracy is 91.0%\n",
            "Using feature(s) [6, 5, 0] accuracy is 87.0%\n",
            "Using feature(s) [6, 5, 1] accuracy is 85.0%\n",
            "Using feature(s) [6, 5, 2] accuracy is 91.0%\n",
            "Using feature(s) [6, 5, 3] accuracy is 96.0%\n",
            "Using feature(s) [6, 5, 4] accuracy is 94.0%\n",
            "Using feature(s) [6, 5, 7] accuracy is 93.0%\n",
            "Using feature(s) [6, 5, 8] accuracy is 88.0%\n",
            "Using feature(s) [6, 5, 9] accuracy is 92.0%\n",
            "Using feature(s) [6, 5, 10] accuracy is 88.0%\n",
            "Using feature(s) [6, 5, 11] accuracy is 86.0%\n",
            "Finished search!! The best feature subset is [6, 5], which has an accuracy of 94.0%\n",
            "\n",
            "Backward Elimination\n",
            "Finished search!! The best feature subset is [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11], which has an accuracy of 68.0%\n",
            "\n"
          ]
        }
      ]
    }
  ]
}